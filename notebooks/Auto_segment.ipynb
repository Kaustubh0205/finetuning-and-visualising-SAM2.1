{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlQldL3jabH4",
        "outputId": "4b981ca9-5b28-441d-c322-5a6ef7745d95"
      },
      "outputs": [],
      "source": [
        "#This program was runening on Google Colab, so the paths are set to /content/data/\n",
        "#If you are running this on your local machine, change the paths accordingly\n",
        "#set your cwd as home directory\n",
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-yDLKR2blmu",
        "outputId": "3a0d8be0-f463-4c64-e7d7-babd9adf12cc"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAzcp9X9agOf",
        "outputId": "c8264968-c0a4-488c-f05c-a6b11789df3a"
      },
      "outputs": [],
      "source": [
        "# Install model if you did not do it yet\n",
        "!git clone https://github.com/facebookresearch/segment-anything-2.git\n",
        "!pip install -e . -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja3PlSIPakSZ",
        "outputId": "3b327040-fe0f-4dd1-cd2b-9a3366ea44d2"
      },
      "outputs": [],
      "source": [
        "!pip install -q supervision jupyter_bbox_widget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmEYUi3Yao3Z"
      },
      "outputs": [],
      "source": [
        "#can install the model weights but I included them in the repo\n",
        "!mkdir -p {HOME}/checkpoints\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt -P {HOME}/checkpoints\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt -P {HOME}/checkpoints\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt -P {HOME}/checkpoints\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt -P {HOME}/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch7wyx4IaQk_",
        "outputId": "a24c6b04-d361-434c-dfd3-55e40989bcb8"
      },
      "outputs": [],
      "source": [
        "#install roboflow and download the dataset\n",
        "%cd {HOME}\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"your_api_key_here\")\n",
        "project = rf.workspace(\"roboflow_workspacename\").project(\"projectname\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"sam2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbwf0KSxaT5A"
      },
      "outputs": [],
      "source": [
        "#rename the dataset folder to data\n",
        "import os\n",
        "\n",
        "os.rename(\"/content/wing_segment-1\", \"/content/data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ4N0c5ZazGW",
        "outputId": "c39a0cc9-dafd-45e3-b1af-6963c77c2d2d"
      },
      "outputs": [],
      "source": [
        "#change cwd to the segment-anything-2 directory\n",
        "#import necessary libraries\n",
        "%cd {HOME}/segment-anything-2\n",
        "import cv2\n",
        "import torch\n",
        "import base64\n",
        "\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZTiVIq0a3VH"
      },
      "outputs": [],
      "source": [
        "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
        "\n",
        "if torch.cuda.get_device_properties(0).major >= 8:\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC6wXlAWa7ws"
      },
      "outputs": [],
      "source": [
        "#save the config file in /content/segment-anything-2/sam2\n",
        "#build the fine tuned model\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "CHECKPOINT = f\"{HOME}finetuned_weight path\"\n",
        "CONFIG = \"sam2.1_hiera_b+ (1).yaml\"\n",
        "\n",
        "sam2_model = build_sam2(CONFIG, CHECKPOINT, device=DEVICE, apply_postprocessing=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySEduP1iwWUK"
      },
      "outputs": [],
      "source": [
        "#build the base model amd mask generator\n",
        "checkpoint_base = f\"{HOME}/checkpoints/sam2_hiera_large.pt\"\n",
        "model_cfg_base = \"sam2_hiera_l.yaml\"\n",
        "sam2_base = build_sam2(model_cfg_base, checkpoint_base, device=\"cuda\")\n",
        "mask_generator_base = SAM2AutomaticMaskGenerator(sam2_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeAYxvyJa_b3"
      },
      "outputs": [],
      "source": [
        "#build the fine tuned model mask generator\n",
        "%cd {HOME}\n",
        "mask_generator = SAM2AutomaticMaskGenerator(sam2_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "BDnYsb-3bD8p",
        "outputId": "6e486f18-b1ac-48f3-9f33-6a28be08049c"
      },
      "outputs": [],
      "source": [
        "# Load an image from the dataset\n",
        "import cv2\n",
        "IMAGE_PATH = f\"{HOME}/YOUR_IMAGE_PATH_HERE.jpg\"  # Replace with your image path\n",
        "\n",
        "image_bgr = cv2.imread(IMAGE_PATH)\n",
        "# Resize the image\n",
        "image_bgr = cv2.resize(image_bgr, (image_bgr.shape[1] // 4, image_bgr.shape[0] // 4))  # Resize by half\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "sam2_result = mask_generator.generate(image_rgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "O4I0ZF8pbIcD",
        "outputId": "c31db7c4-6764-47d0-c296-5d61168ed772"
      },
      "outputs": [],
      "source": [
        "# generate masks using the fine tuned model\n",
        "mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "detections = sv.Detections.from_sam(sam_result=sam2_result)\n",
        "\n",
        "annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=[image_bgr, annotated_image],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['source image', 'segmented image']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v8cL-XogunB6",
        "outputId": "8e2fbc1a-22c5-4d35-be41-2db739d18e10"
      },
      "outputs": [],
      "source": [
        "#visualizing results of the base and fine tuned model\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "validation_set = os.listdir(\"Your path to the validation set\")  # Replace with your validation set path\n",
        "\n",
        "# Filter for image files (e.g., .jpg, .png)\n",
        "image_files = [img for img in validation_set if img.endswith((\".jpg\", \".png\"))]\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(\"Your path to the validation set\", image_file)\n",
        "    opened_image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "\n",
        "    result = mask_generator.generate(opened_image)\n",
        "    detections = sv.Detections.from_sam(sam_result=result)\n",
        "\n",
        "    mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "    annotated_image = opened_image.copy()\n",
        "    annotated_image = mask_annotator.annotate(annotated_image, detections=detections)\n",
        "    base_result = mask_generator_base.generate(opened_image)\n",
        "    base_detections = sv.Detections.from_sam(sam_result=base_result)\n",
        "\n",
        "    base_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "    base_annotated_image = opened_image.copy()\n",
        "    base_annotated_image = base_annotator.annotate(base_annotated_image, detections=base_detections)\n",
        "\n",
        "    # Plot the images\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))  # Adjust figsize as needed\n",
        "    axes[0].imshow(annotated_image)\n",
        "    axes[0].set_title(\"Fine-tuned SAM\")\n",
        "    axes[0].axis(\"off\")\n",
        "    axes[1].imshow(base_annotated_image)\n",
        "    axes[1].set_title(\"Base SAM\")\n",
        "    axes[1].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QcGXDRUzNF0g",
        "outputId": "f267b526-fb74-42c0-d4e5-c2d9dcc75f8f"
      },
      "outputs": [],
      "source": [
        "#generate binary masks for visualization\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import supervision as sv\n",
        "\n",
        "validation_set = os.listdir(\"/content/data/valid\")\n",
        "image_files = [img for img in validation_set if img.endswith((\".jpg\", \".png\"))]\n",
        "\n",
        "# Make sure you are using the original mask_generator_2 object\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(\"/content/data/valid\", image_file)\n",
        "    opened_image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "\n",
        "    # Use mask_generator_2 to generate results, and store results in a new variable\n",
        "    result = mask_generator_2.generate(opened_image)\n",
        "\n",
        "    # Get binary masks\n",
        "    masks = [\n",
        "        mask['segmentation']\n",
        "        for mask in sorted(result, key=lambda x: x['area'], reverse=True)\n",
        "    ]\n",
        "\n",
        "    # Plot the binary masks\n",
        "    sv.plot_images_grid(\n",
        "        images=masks[:16],  # Adjust the number of masks to display\n",
        "        grid_size=(4, 4),  # Adjust grid size as needed\n",
        "        size=(12, 12)     # Adjust figure size as needed\n",
        "    )\n",
        "    plt.show()  # Display the plot for each image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la_TZVjRLK92"
      },
      "outputs": [],
      "source": [
        "# extra parameters for the mask generator\n",
        "mask_generator_2 = SAM2AutomaticMaskGenerator(\n",
        "    model=sam2_model,\n",
        "    points_per_side=64,\n",
        "    points_per_batch=128,\n",
        "    pred_iou_thresh=0.7,\n",
        "    stability_score_thresh=0.92,\n",
        "    stability_score_offset=0.7,\n",
        "    crop_n_layers=1,\n",
        "    box_nms_thresh=0.7,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC7GHci2LVO5"
      },
      "outputs": [],
      "source": [
        "mask_generator = mask_generator_2.generate(opened_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG_TOmXbCK4w"
      },
      "outputs": [],
      "source": [
        "# Generate masks for the validation set and save them to JSON files\n",
        "validation_set = os.listdir(\"/content/data/valid\")\n",
        "image_files = [img for img in validation_set if img.endswith((\".jpg\", \".png\"))]\n",
        "output_dir = \"mask_jsons\"  # Create a directory to store JSON files\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(\"/content/data/valid\", image_file)\n",
        "    opened_image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "\n",
        "    result = mask_generator.generate(opened_image)\n",
        "    # The result from mask_generator.generate is a list of dictionaries\n",
        "    # Each dictionary contains the segmentation mask and other information\n",
        "\n",
        "    # Extract masks directly from the result\n",
        "    masks = [mask_data['segmentation'] for mask_data in result]\n",
        "\n",
        "    # Save masks to JSON\n",
        "    save_masks_to_json(masks, image_path, output_dir)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "pytorch_nocuda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
